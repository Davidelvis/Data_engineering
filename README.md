# Data_engineering
Docker is an open-source platform, where we can automate our project deployment, software application deployment and we can deploy any of our trained deep learning, machine learning models inside CONTAINERS which not only makes it easier for production but also it adds automation and abstraction.

Data which is said to be new oil, needs to be transported to where it is processed, and this is made efficient using data pipelines.

In this repository, I learn on how to make data pipelines and run them in docker containers
